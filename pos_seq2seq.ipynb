{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:57:35.212830Z",
     "iopub.status.busy": "2022-09-04T13:57:35.211998Z",
     "iopub.status.idle": "2022-09-04T13:57:37.759692Z",
     "shell.execute_reply": "2022-09-04T13:57:37.758471Z",
     "shell.execute_reply.started": "2022-09-04T13:57:35.212732Z"
    },
    "id": "o57-A7azLY8F"
   },
   "outputs": [],
   "source": [
    "#library imports\n",
    "# !pip install hazm\n",
    "# !pip install fasttext\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from torch.utils.data import Dataset, DataLoader, Sampler\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error\n",
    "# from hazm import *\n",
    "# import fasttext.util\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:57:37.766784Z",
     "iopub.status.busy": "2022-09-04T13:57:37.764804Z",
     "iopub.status.idle": "2022-09-04T13:58:48.924804Z",
     "shell.execute_reply": "2022-09-04T13:58:48.923680Z",
     "shell.execute_reply.started": "2022-09-04T13:57:37.766746Z"
    },
    "id": "pxLHf-wKe7TK",
    "outputId": "d5e60e58-2f7c-4c33-9360-ceba6917b76b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting gdown\n",
      "  Downloading gdown-4.5.1.tar.gz (14 kB)\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: requests[socks] in /opt/conda/lib/python3.7/site-packages (from gdown) (2.28.1)\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.7/site-packages (from gdown) (1.15.0)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.7/site-packages (from gdown) (3.7.1)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.7/site-packages (from gdown) (4.64.0)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.7/site-packages (from gdown) (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.7/site-packages (from beautifulsoup4->gdown) (2.3.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2022.6.15)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.26.12)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (2.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (3.3)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /opt/conda/lib/python3.7/site-packages (from requests[socks]->gdown) (1.7.1)\n",
      "Building wheels for collected packages: gdown\n",
      "  Building wheel for gdown (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for gdown: filename=gdown-4.5.1-py3-none-any.whl size=14933 sha256=e9573b9abf61e31f0bbd82400eb296e8134fb5f9e3727727843853de54d48f08\n",
      "  Stored in directory: /root/.cache/pip/wheels/3d/ec/b0/a96d1d126183f98570a785e6bf8789fca559853a9260e928e1\n",
      "Successfully built gdown\n",
      "Installing collected packages: gdown\n",
      "Successfully installed gdown-4.5.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  unrar\n",
      "0 upgraded, 1 newly installed, 0 to remove and 56 not upgraded.\n",
      "Need to get 113 kB of archives.\n",
      "After this operation, 406 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu focal/multiverse amd64 unrar amd64 1:5.6.6-2build1 [113 kB]\n",
      "Fetched 113 kB in 0s (441 kB/s) \n",
      "Selecting previously unselected package unrar.\n",
      "(Reading database ... 108827 files and directories currently installed.)\n",
      "Preparing to unpack .../unrar_1%3a5.6.6-2build1_amd64.deb ...\n",
      "Unpacking unrar (1:5.6.6-2build1) ...\n",
      "Setting up unrar (1:5.6.6-2build1) ...\n",
      "update-alternatives: using /usr/bin/unrar-nonfree to provide /usr/bin/unrar (unrar) in auto mode\n",
      "update-alternatives: warning: skip creation of /usr/share/man/man1/unrar.1.gz because associated file /usr/share/man/man1/unrar-nonfree.1.gz (of link group unrar) doesn't exist\n",
      "Processing triggers for man-db (2.9.1-1) ...\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1kVtPrMsqn_u4RfPD4QWaBcz8rv1F-UXC\n",
      "To: /kaggle/working/posdataset.rar\n",
      "100%|███████████████████████████████████████| 39.8M/39.8M [00:00<00:00, 196MB/s]\n",
      "\n",
      "UNRAR 5.61 beta 1 freeware      Copyright (c) 1993-2018 Alexander Roshal\n",
      "\n",
      "\n",
      "Extracting from posdataset.rar\n",
      "\n",
      "Extracting  data/dev.conll                                               6  OK \n",
      "Extracting  data/test.conll                                             13  OK \n",
      "Extracting  data/train.conll                                            2 3 4 5 6 7 8 9 99  OK \n",
      "All OK\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=17_rYUnNpZNsp88eslUHRC29xzcTeMBfg\n",
      "To: /kaggle/working/vocab2index.json\n",
      "100%|███████████████████████████████████████| 5.67M/5.67M [00:00<00:00, 227MB/s]\n",
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1uyGCAWBC-EuMeXmPxGRVXALZpwDjjygC\n",
      "To: /kaggle/working/word_vector_dic.json\n",
      "100%|█████████████████████████████████████████| 780M/780M [00:02<00:00, 305MB/s]\n"
     ]
    }
   ],
   "source": [
    "f = open ('vocab2index.json', \"r\")\n",
    "vocab2index = json.loads(f.read())\n",
    "f = open ('word_vector_dic.json', \"r\")\n",
    "word_vector_dic = json.loads(f.read())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:58:48.927129Z",
     "iopub.status.busy": "2022-09-04T13:58:48.926674Z",
     "iopub.status.idle": "2022-09-04T13:58:52.070680Z",
     "shell.execute_reply": "2022-09-04T13:58:52.069685Z",
     "shell.execute_reply.started": "2022-09-04T13:58:48.927074Z"
    },
    "id": "TYi7SFL3MyjY"
   },
   "outputs": [],
   "source": [
    "train_path = 'data/train.conll'\n",
    "train_lines = [line for line in open(train_path)]\n",
    "\n",
    "test_path = 'data/test.conll'\n",
    "test_lines = [line for line in open(test_path)]\n",
    "\n",
    "val_path = 'data/dev.conll'\n",
    "val_lines = [line for line in open(val_path)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:58:52.074433Z",
     "iopub.status.busy": "2022-09-04T13:58:52.073979Z",
     "iopub.status.idle": "2022-09-04T13:59:22.040268Z",
     "shell.execute_reply": "2022-09-04T13:59:22.039070Z",
     "shell.execute_reply.started": "2022-09-04T13:58:52.074393Z"
    },
    "id": "djYR3mySG0ZB",
    "outputId": "564d7599-363c-490a-d9ab-6009508d97d5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 سالهاست سالهاست V 1 V\n",
      "2 که که CONJ 2 CONJ\n",
      "3 کشورهای کشورهای N 3 N\n",
      "4 پیشرفته پیشرفته AJ 3 AJ\n",
      "5 و و CONJ 5 CONJ\n",
      "6 در در P 6 P\n",
      "7 حال حال N 7 N\n",
      "8 توسعه توسعه N 7 N\n",
      "9 جهان جهان N 8 N\n",
      "10 استفاده استفاده N 10 N\n",
      "11 از از P 11 P\n",
      "12 روش روش N 12 N\n",
      "13 یک یک NUM 12 NUM\n",
      "14 کتابی کتابی AJ 14 AJ\n",
      "15 را را POSTP 15 POSTP\n",
      "16 در در P 16 P\n",
      "17 تدریس تدریس N 17 N\n",
      "18 ترک ترک N 18 N\n",
      "19 گفته گفته V 19 V\n",
      "20 و و CONJ 20 CONJ\n",
      "21 راه راه N 21 N\n",
      "22 مواد مواد N 21 N\n",
      "23 خواندنی خواندنی AJ 22 AJ\n",
      "24 بی‌شمار بی‌شمار AJ 23 AJ\n",
      "25 دیگری دیگری PRO 24 PRO\n",
      "26 را را POSTP 26 POSTP\n",
      "27 برای برای P 27 P\n",
      "28 تکمیل تکمیل N 27 N\n",
      "29 برنامه برنامه N 28 N\n",
      "30 درسی درسی AJ 29 AJ\n",
      "31 به به P 31 P\n",
      "32 کلاس کلاس N 32 N\n",
      "33 باز باز AJ 33 AJ\n",
      "34 کرده‌اند کرده‌اند V 34 V\n",
      "35 . . PUNC 35 PUNC\n",
      "1 این این DET 1 DET\n",
      "2 مدرسه مدرسه N 2 N\n",
      "3 در در P 3 P\n",
      "4 منطقه منطقه N 4 N\n",
      "5 14 14 NUM 4 NUM\n",
      "6 آموزش آموزش N 5 N\n",
      "7 و و CONJ 7 CONJ\n",
      "8 پرورش پرورش N 8 N\n",
      "9 قرار قرار N 9 N\n",
      "10 دارد دارد V 10 V\n",
      "11 . . PUNC 11 PUNC\n",
      "1 نقد نقد N 1 N\n",
      "2 فیلم فیلم N 1 N\n",
      "3 » » PUNC 3 PUNC\n",
      "4 زشت زشت AJ 4 AJ\n",
      "5 و و CONJ 5 CONJ\n",
      "6 زیبا زیبا AJ 6 AJ\n",
      "7 « « PUNC 7 PUNC\n",
      "8 # # PUNC 8 PUNC\n"
     ]
    }
   ],
   "source": [
    "max_lenth = 30\n",
    "sos = \"sos\"\n",
    "eos = \"eos\"\n",
    "punc = \"PUNC\"\n",
    "def data_reader(lines):\n",
    "    map_sents = []\n",
    "    sents, sent = [], []\n",
    "    all_ezafe_tags = []\n",
    "    all_pos_tags, pos_tags = [], []\n",
    "    pos_to_id = {}\n",
    "    for i, line in enumerate(lines):\n",
    "            if line != '\\n':\n",
    "                index, word1, word2,pos_tag1, _, _,kasre_rel, pos_tag2, _, _ = line.strip().split('\\t')\n",
    "\n",
    "                sent = sent + [word1]\n",
    "                if len(map_sents) == 15:\n",
    "                  print(index, word1, word2,pos_tag1,kasre_rel, pos_tag2)\n",
    "                \n",
    "                ezafe_tag = 0\n",
    "                if lines[i+1] != '\\n':\n",
    "                  ezafe_tag = 1 if index == lines[i+1].strip().split('\\t')[6] else 0\n",
    "                \n",
    "                if ezafe_tag == 1:\n",
    "                  pos_tag1 = pos_tag1 + \"E\"\n",
    "\n",
    "                if pos_tag1 not in pos_to_id:\n",
    "                    pos_to_id[pos_tag1] = len(pos_to_id)\n",
    "\n",
    "                pos_tags = pos_tags + [pos_tag1]\n",
    "            else:\n",
    "                sent = [sos] + sent[:max_lenth-3] + [\".\"] + [eos]\n",
    "                pos_tags = [sos] + pos_tags[:max_lenth-3] + [punc] + [eos]\n",
    "                map_sents.append({\"sent\" : sent,\"pos_tags\" : pos_tags})\n",
    "                ezafe_tags = []\n",
    "                pos_tags = []\n",
    "                sent = []\n",
    "\n",
    "    map_sents = list(sorted(map_sents, key=lambda d: len(d['sent']), reverse=True)) \n",
    "    return map_sents\n",
    "\n",
    "train_map_sents = data_reader(train_lines)\n",
    "test_map_sents = data_reader(test_lines)\n",
    "val_map_sents = data_reader(val_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:22.042314Z",
     "iopub.status.busy": "2022-09-04T13:59:22.041895Z",
     "iopub.status.idle": "2022-09-04T13:59:26.919475Z",
     "shell.execute_reply": "2022-09-04T13:59:26.918343Z",
     "shell.execute_reply.started": "2022-09-04T13:59:22.042275Z"
    },
    "id": "kO_zieKE8x9q",
    "outputId": "6b7b04fd-842d-434a-9a22-468e71da7434"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100820\n"
     ]
    }
   ],
   "source": [
    "df_train = pd.DataFrame.from_dict(train_map_sents)\n",
    "df_test = pd.DataFrame.from_dict(test_map_sents)\n",
    "df_val = pd.DataFrame.from_dict(val_map_sents)\n",
    "\n",
    "all_words = []\n",
    "def fetch_words(sent):\n",
    "  all_words.extend(sent)\n",
    "\n",
    "df_train.apply(lambda row : fetch_words(row['sent']), axis = 1)\n",
    "df_test.apply(lambda row : fetch_words(row['sent']), axis = 1)\n",
    "df_val.apply(lambda row : fetch_words(row['sent']), axis = 1)\n",
    "all_words = list(set(all_words))\n",
    "print(len(all_words))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:26.921406Z",
     "iopub.status.busy": "2022-09-04T13:59:26.920935Z",
     "iopub.status.idle": "2022-09-04T13:59:26.931603Z",
     "shell.execute_reply": "2022-09-04T13:59:26.929464Z",
     "shell.execute_reply.started": "2022-09-04T13:59:26.921368Z"
    },
    "id": "1WQjhu13KKq7",
    "outputId": "549c3561-c958-4665-8ab5-0ce4f12e0885"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sos sos\n",
      "روشهای NE\n",
      "مختلف AJ\n",
      "در P\n",
      "علاقمند AJ\n",
      "کردن NE\n",
      "کودکان N\n",
      "به P\n",
      "مطالعه NE\n",
      "نظام NE\n",
      "تعلیم N\n",
      "و CONJ\n",
      "تربیت N\n",
      "، PUNC\n",
      "روشهای NE\n",
      "تدریس NE\n",
      "کتابهای NE\n",
      "درسی AJ\n",
      "و CONJ\n",
      "نحوه NE\n",
      "کار NE\n",
      "معلم N\n",
      "با P\n",
      "وسایل NE\n",
      "ارتباط N\n",
      "جمعی AJ\n",
      "در P\n",
      "خانواده N\n",
      ". PUNC\n",
      "eos eos\n"
     ]
    }
   ],
   "source": [
    "index = 15\n",
    "for i in range(len(df_train[\"sent\"][index])):\n",
    "  print(df_train[\"sent\"][index][i],df_train[\"pos_tags\"][index][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:26.934534Z",
     "iopub.status.busy": "2022-09-04T13:59:26.933407Z",
     "iopub.status.idle": "2022-09-04T13:59:30.723007Z",
     "shell.execute_reply": "2022-09-04T13:59:30.721948Z",
     "shell.execute_reply.started": "2022-09-04T13:59:26.934498Z"
    },
    "id": "ON0pNEKMaRLJ",
    "outputId": "8836ba79-e3e6-4e71-ba0b-179f494e935c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n",
      "{'DET': 0, 'PUNC': 1, 'sos': 2, 'DETE': 3, 'PAD': 4, 'NE': 5, 'V': 6, 'RESE': 7, 'AJE': 8, 'INT': 9, 'ADVE': 10, 'AJCC': 11, 'N': 12, 'RES': 13, 'PRO': 14, 'AJ': 15, 'POSTP': 16, 'CL': 17, 'P': 18, 'CONJE': 19, 'CONJ': 20, 'NUM': 21, 'PE': 22, 'NUME': 23, 'eos': 24, 'ADV': 25, 'PROE': 26}\n"
     ]
    }
   ],
   "source": [
    "all_tags = []\n",
    "def fetch_pos(pos_tags):\n",
    "  all_tags.extend(pos_tags)\n",
    "\n",
    "df_train.apply(lambda row : fetch_pos(row['pos_tags']), axis = 1)\n",
    "df_test.apply(lambda row : fetch_pos(row['pos_tags']), axis = 1)\n",
    "df_val.apply(lambda row : fetch_pos(row['pos_tags']), axis = 1)\n",
    "\n",
    "all_tags = all_tags + [\"PAD\"]\n",
    "all_tags = list(set(all_tags))\n",
    "pos2index = {k: v for v, k in enumerate(all_tags)}\n",
    "print(len(all_tags))\n",
    "print(pos2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:30.725053Z",
     "iopub.status.busy": "2022-09-04T13:59:30.724696Z",
     "iopub.status.idle": "2022-09-04T13:59:35.749218Z",
     "shell.execute_reply": "2022-09-04T13:59:35.748269Z",
     "shell.execute_reply.started": "2022-09-04T13:59:30.725018Z"
    },
    "id": "USjgmn-YZF1X",
    "outputId": "d24c50f4-4dbd-49f8-e8e6-a9400882404e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  if __name__ == \"__main__\":\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:11: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "def encode_sentence(text, vocab2index, N):\n",
    "    encoded = np.full((N), vocab2index[\"PAD\"])\n",
    "    enc1 = np.array([vocab2index[word] for word in text])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length\n",
    "\n",
    "\n",
    "df_train['encoded_sent'] = df_train['sent'].apply(lambda x: np.array(encode_sentence(x,vocab2index,max_lenth)))\n",
    "df_test['encoded_sent'] = df_test['sent'].apply(lambda x: np.array(encode_sentence(x,vocab2index,max_lenth)))\n",
    "df_val['encoded_sent'] = df_val['sent'].apply(lambda x: np.array(encode_sentence(x,vocab2index,max_lenth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:35.752282Z",
     "iopub.status.busy": "2022-09-04T13:59:35.751889Z",
     "iopub.status.idle": "2022-09-04T13:59:39.859427Z",
     "shell.execute_reply": "2022-09-04T13:59:39.857040Z",
     "shell.execute_reply.started": "2022-09-04T13:59:35.752245Z"
    },
    "id": "pFkIUSh4Zt9b",
    "outputId": "ac608abe-da89-4eef-c0bb-d5d623a2caf5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:8: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  if __name__ == \"__main__\":\n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def encode_pos(pos_tags, pos2index, N):\n",
    "    encoded = np.full((N), pos2index[\"PAD\"], dtype=int)\n",
    "    enc1 = np.array([pos2index[pos_tag] for pos_tag in pos_tags])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length\n",
    "\n",
    "df_train['encoded_pos'] = df_train['pos_tags'].apply(lambda x: np.array(encode_pos(x,pos2index,max_lenth)))\n",
    "df_test['encoded_pos'] = df_test['pos_tags'].apply(lambda x: np.array(encode_pos(x,pos2index,max_lenth)))\n",
    "df_val['encoded_pos'] = df_val['pos_tags'].apply(lambda x: np.array(encode_pos(x,pos2index,max_lenth)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:39.865093Z",
     "iopub.status.busy": "2022-09-04T13:59:39.864159Z",
     "iopub.status.idle": "2022-09-04T13:59:39.872504Z",
     "shell.execute_reply": "2022-09-04T13:59:39.871378Z",
     "shell.execute_reply.started": "2022-09-04T13:59:39.865041Z"
    },
    "id": "wVXUVyYsS-WM",
    "outputId": "1ad3c88b-9126-49aa-f0c2-a5cd8289e35b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n",
      "['sos', 'مجموعه', 'اظهارات', 'مسئولان', 'و', 'بررسیهای', 'گوناگون', 'که', 'از', 'سوی', 'بعضی', 'پژوهشگران', 'و', 'علاقه', 'مندان', 'در', 'زمینه', 'کتابخانه\\u200cهای', 'آموزشگاهی', 'به', 'عمل', 'آمده', 'است', '،', 'نشانگر', 'کمبودها', 'و', 'نارسائیهای', '.', 'eos']\n",
      "[array([ 2,  5,  5, 12, 20,  5, 15, 20, 18,  5,  0, 12, 20, 12, 12, 18,  5,\n",
      "         5, 15, 18, 12,  6,  6,  1,  5, 12, 20,  5,  1, 24])\n",
      " 30]\n"
     ]
    }
   ],
   "source": [
    "index = 1\n",
    "print(pos2index[\"PAD\"])\n",
    "print(df_train['sent'][index])\n",
    "print(df_train['encoded_pos'][index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:39.874664Z",
     "iopub.status.busy": "2022-09-04T13:59:39.874300Z",
     "iopub.status.idle": "2022-09-04T13:59:39.885217Z",
     "shell.execute_reply": "2022-09-04T13:59:39.884266Z",
     "shell.execute_reply.started": "2022-09-04T13:59:39.874621Z"
    },
    "id": "4nl6hFNlMHdm"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "import random\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:39.888062Z",
     "iopub.status.busy": "2022-09-04T13:59:39.887554Z",
     "iopub.status.idle": "2022-09-04T13:59:39.956363Z",
     "shell.execute_reply": "2022-09-04T13:59:39.954899Z",
     "shell.execute_reply.started": "2022-09-04T13:59:39.888028Z"
    },
    "id": "ug5FYNVGUPDe",
    "outputId": "0d880815-5ed2-4bfb-ae46-253f012c130e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:39.959414Z",
     "iopub.status.busy": "2022-09-04T13:59:39.957897Z",
     "iopub.status.idle": "2022-09-04T13:59:39.968283Z",
     "shell.execute_reply": "2022-09-04T13:59:39.967118Z",
     "shell.execute_reply.started": "2022-09-04T13:59:39.959375Z"
    },
    "id": "_3WqmeZSZsvH"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "class SentDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), torch.from_numpy(self.y[idx][0].astype(np.int32)), torch.tensor(max_lenth, dtype=torch.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:39.970996Z",
     "iopub.status.busy": "2022-09-04T13:59:39.970143Z",
     "iopub.status.idle": "2022-09-04T13:59:40.562582Z",
     "shell.execute_reply": "2022-09-04T13:59:40.561482Z",
     "shell.execute_reply.started": "2022-09-04T13:59:39.970959Z"
    },
    "id": "tgrnXBGBpnZh",
    "outputId": "9a09c4e5-c96f-44f8-d1ff-16faa9616c1d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "304798\n",
      "19046\n",
      "21715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "BATCH_SIZE = 1024\n",
    "\n",
    "train_dataset = SentDataset(df_train['encoded_sent'], df_train['encoded_pos'])\n",
    "valid_dataset = SentDataset(df_val['encoded_sent'], df_val['encoded_pos'])\n",
    "test_dataset = SentDataset(df_test['encoded_sent'], df_test['encoded_pos'])\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(valid_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "\n",
    "train_dl = DataLoader(train_dataset, batch_size=BATCH_SIZE,num_workers=2,pin_memory=True, shuffle=False)\n",
    "val_dl = DataLoader(valid_dataset, batch_size=BATCH_SIZE,num_workers=2,pin_memory=True,)\n",
    "test_dl = DataLoader(test_dataset, batch_size=BATCH_SIZE,num_workers=2,pin_memory=True,)\n",
    "\n",
    "\n",
    "del(train_lines,test_lines,val_lines)\n",
    "del(train_map_sents,test_map_sents,val_map_sents)\n",
    "del(train_dataset,valid_dataset,test_dataset)\n",
    "del(all_words,all_tags)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:40.564761Z",
     "iopub.status.busy": "2022-09-04T13:59:40.563888Z",
     "iopub.status.idle": "2022-09-04T13:59:40.571134Z",
     "shell.execute_reply": "2022-09-04T13:59:40.570018Z",
     "shell.execute_reply.started": "2022-09-04T13:59:40.564726Z"
    },
    "id": "zLD_nmvtPm33",
    "outputId": "57b6c7c9-a271-4185-913d-b3c3873c937e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117164\n",
      "117166\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(len(word_vector_dic.keys()))\n",
    "print(len(vocab2index.keys()))\n",
    "print(vocab2index[\"PAD\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:40.573431Z",
     "iopub.status.busy": "2022-09-04T13:59:40.572479Z",
     "iopub.status.idle": "2022-09-04T13:59:42.021062Z",
     "shell.execute_reply": "2022-09-04T13:59:42.019954Z",
     "shell.execute_reply.started": "2022-09-04T13:59:40.573395Z"
    },
    "id": "M16nmYxw1EHo"
   },
   "outputs": [],
   "source": [
    "def get_emb_matrix(emb_size = 300):\n",
    "    \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
    "    vocab_size = len(word_vector_dic.keys()) + 2\n",
    "    vocab_to_idx = {}\n",
    "    vocab = [\"PAD\", \"UNK\"]\n",
    "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
    "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
    "    vocab_to_idx[\"PAD\"] = 0\n",
    "    vocab_to_idx[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in word_vector_dic.keys():\n",
    "        if word in word_vector_dic:\n",
    "            W[i] = word_vector_dic[word]\n",
    "        else:\n",
    "            print(word)\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab_to_idx[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1   \n",
    "    return W, vocab_to_idx, vocab_size\n",
    "\n",
    "pretrained_weights, vocab2index, vocab_size = get_emb_matrix(emb_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:42.024542Z",
     "iopub.status.busy": "2022-09-04T13:59:42.023828Z",
     "iopub.status.idle": "2022-09-04T13:59:42.053988Z",
     "shell.execute_reply": "2022-09-04T13:59:42.052717Z",
     "shell.execute_reply.started": "2022-09-04T13:59:42.024504Z"
    },
    "id": "-GHgqArCd3zX"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, input_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, pad_idx, weights):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.embedding = nn.Embedding(input_dim, emb_dim, padding_idx = pad_idx)\n",
    "        self.embedding.weight.data.copy_(torch.from_numpy(weights).cuda())\n",
    "        self.embedding.weight.requires_grad = False\n",
    "        \n",
    "        \n",
    "        self.rnn = nn.GRU(emb_dim, enc_hid_dim, bidirectional = True)\n",
    "        \n",
    "        self.fc = nn.Linear(enc_hid_dim * 2, dec_hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_len):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(src))\n",
    "        \n",
    "        #embedded = [src len, batch size, emb dim]\n",
    "                \n",
    "        #need to explicitly put lengths on cpu!\n",
    "        packed_embedded = nn.utils.rnn.pack_padded_sequence(embedded, src_len.to('cpu'))\n",
    "                \n",
    "        packed_outputs, hidden = self.rnn(packed_embedded)\n",
    "                                 \n",
    "        #packed_outputs is a packed sequence containing all hidden states\n",
    "        #hidden is now from the final non-padded element in the batch\n",
    "            \n",
    "        outputs, _ = nn.utils.rnn.pad_packed_sequence(packed_outputs) \n",
    "            \n",
    "        #outputs is now a non-packed sequence, all hidden states obtained\n",
    "        #  when the input is a pad token are all zeros\n",
    "            \n",
    "        #outputs = [src len, batch size, hid dim * num directions]\n",
    "        #hidden = [n layers * num directions, batch size, hid dim]\n",
    "        \n",
    "        #hidden is stacked [forward_1, backward_1, forward_2, backward_2, ...]\n",
    "        #outputs are always from the last layer\n",
    "        \n",
    "        #hidden [-2, :, : ] is the last of the forwards RNN \n",
    "        #hidden [-1, :, : ] is the last of the backwards RNN\n",
    "        \n",
    "        #initial decoder hidden is final hidden state of the forwards and backwards \n",
    "        #  encoder RNNs fed through a linear layer\n",
    "        hidden = torch.tanh(self.fc(torch.cat((hidden[-2,:,:], hidden[-1,:,:]), dim = 1)))\n",
    "        \n",
    "        #outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        \n",
    "        return outputs, hidden\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self, enc_hid_dim, dec_hid_dim):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attn = nn.Linear((enc_hid_dim * 2) + dec_hid_dim, dec_hid_dim)\n",
    "        self.v = nn.Linear(dec_hid_dim, 1, bias = False)\n",
    "        \n",
    "    def forward(self, hidden, encoder_outputs, mask):\n",
    "        \n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        \n",
    "        batch_size = encoder_outputs.shape[1]\n",
    "        src_len = encoder_outputs.shape[0]\n",
    "        \n",
    "        #repeat decoder hidden state src_len times\n",
    "        hidden = hidden.unsqueeze(1).repeat(1, src_len, 1)\n",
    "  \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #hidden = [batch size, src len, dec hid dim]\n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        energy = torch.tanh(self.attn(torch.cat((hidden, encoder_outputs), dim = 2))) \n",
    "        \n",
    "        #energy = [batch size, src len, dec hid dim]\n",
    "\n",
    "        attention = self.v(energy).squeeze(2)\n",
    "        \n",
    "        #attention = [batch size, src len]\n",
    "        \n",
    "        attention = attention.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        return F.softmax(attention, dim = 1)\n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, output_dim, emb_dim, enc_hid_dim, dec_hid_dim, dropout, attention):\n",
    "        super().__init__()\n",
    "\n",
    "        self.output_dim = output_dim\n",
    "        self.attention = attention\n",
    "        \n",
    "        self.embedding = nn.Embedding(output_dim, emb_dim)\n",
    "        \n",
    "        self.rnn = nn.GRU((enc_hid_dim * 2) + emb_dim, dec_hid_dim)\n",
    "        \n",
    "        self.fc_out = nn.Linear((enc_hid_dim * 2) + dec_hid_dim + emb_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, input, hidden, encoder_outputs, mask):\n",
    "             \n",
    "        #input = [batch size]\n",
    "        #hidden = [batch size, dec hid dim]\n",
    "        #encoder_outputs = [src len, batch size, enc hid dim * 2]\n",
    "        #mask = [batch size, src len]\n",
    "        \n",
    "        input = input.unsqueeze(0)\n",
    "        \n",
    "        #input = [1, batch size]\n",
    "        \n",
    "        embedded = self.dropout(self.embedding(input))\n",
    "        \n",
    "        #embedded = [1, batch size, emb dim]\n",
    "        \n",
    "        a = self.attention(hidden, encoder_outputs, mask)\n",
    "                \n",
    "        #a = [batch size, src len]\n",
    "        \n",
    "        a = a.unsqueeze(1)\n",
    "        \n",
    "        #a = [batch size, 1, src len]\n",
    "        \n",
    "        encoder_outputs = encoder_outputs.permute(1, 0, 2)\n",
    "        \n",
    "        #encoder_outputs = [batch size, src len, enc hid dim * 2]\n",
    "        \n",
    "        weighted = torch.bmm(a, encoder_outputs)\n",
    "        \n",
    "        #weighted = [batch size, 1, enc hid dim * 2]\n",
    "        \n",
    "        weighted = weighted.permute(1, 0, 2)\n",
    "        \n",
    "        #weighted = [1, batch size, enc hid dim * 2]\n",
    "        \n",
    "        rnn_input = torch.cat((embedded, weighted), dim = 2)\n",
    "        \n",
    "        #rnn_input = [1, batch size, (enc hid dim * 2) + emb dim]\n",
    "            \n",
    "        output, hidden = self.rnn(rnn_input, hidden.unsqueeze(0))\n",
    "        \n",
    "        #output = [seq len, batch size, dec hid dim * n directions]\n",
    "        #hidden = [n layers * n directions, batch size, dec hid dim]\n",
    "        \n",
    "        #seq len, n layers and n directions will always be 1 in this decoder, therefore:\n",
    "        #output = [1, batch size, dec hid dim]\n",
    "        #hidden = [1, batch size, dec hid dim]\n",
    "        #this also means that output == hidden\n",
    "        assert (output == hidden).all()\n",
    "        \n",
    "        embedded = embedded.squeeze(0)\n",
    "        output = output.squeeze(0)\n",
    "        weighted = weighted.squeeze(0)\n",
    "        \n",
    "        prediction = self.fc_out(torch.cat((output, weighted, embedded), dim = 1))\n",
    "        \n",
    "        #prediction = [batch size, output dim]\n",
    "        \n",
    "        return prediction, hidden.squeeze(0), a.squeeze(1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, encoder, decoder, src_pad_idx, device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def create_mask(self, src):\n",
    "        mask = (src != self.src_pad_idx).permute(1, 0)\n",
    "        return mask\n",
    "        \n",
    "    def forward(self, src, src_len, trg, teacher_forcing_ratio = 0.5):\n",
    "        \n",
    "        #src = [src len, batch size]\n",
    "        #src_len = [batch size]\n",
    "        #trg = [trg len, batch size]\n",
    "        #teacher_forcing_ratio is probability to use teacher forcing\n",
    "        #e.g. if teacher_forcing_ratio is 0.75 we use teacher forcing 75% of the time\n",
    "                    \n",
    "        batch_size = src.shape[1]\n",
    "        trg_len = trg.shape[0]\n",
    "        trg_vocab_size = self.decoder.output_dim\n",
    "        \n",
    "        #tensor to store decoder outputs\n",
    "        outputs = torch.zeros(trg_len, batch_size, trg_vocab_size).to(self.device)\n",
    "        \n",
    "        tag_preds = torch.zeros(trg_len, batch_size).to(self.device)\n",
    "        tag_labels = torch.zeros(trg_len, batch_size).to(self.device)\n",
    "        \n",
    "\n",
    "        #encoder_outputs is all hidden states of the input sequence, back and forwards\n",
    "        #hidden is the final forward and backward hidden states, passed through a linear layer\n",
    "        encoder_outputs, hidden = self.encoder(src, src_len)\n",
    "                \n",
    "        #first input to the decoder is the <sos> tokens\n",
    "        input = trg[0,:]\n",
    "        \n",
    "        mask = self.create_mask(src)\n",
    "\n",
    "        #mask = [batch size, src len]\n",
    "                \n",
    "        for t in range(1, trg_len):\n",
    "            \n",
    "            #insert input token embedding, previous hidden state, all encoder hidden states \n",
    "            #  and mask\n",
    "            #receive output tensor (predictions) and new hidden state\n",
    "            output, hidden, _ = self.decoder(input, hidden, encoder_outputs, mask)\n",
    "            \n",
    "            #place predictions in a tensor holding predictions for each token\n",
    "            outputs[t] = output\n",
    "            \n",
    "            #decide if we are going to use teacher forcing or not\n",
    "            teacher_force = random.random() < teacher_forcing_ratio\n",
    "            \n",
    "            #get the highest predicted token from our predictions\n",
    "            top1 = output.argmax(1) \n",
    "            tag_preds[t] = top1\n",
    "            \n",
    "            \n",
    "            #if teacher forcing, use actual next token as next input\n",
    "            #if not, use predicted token\n",
    "            input = trg[t] if teacher_force else top1\n",
    "            tag_labels[t] = trg[t]\n",
    "            \n",
    "        return outputs, torch.flatten(tag_labels), torch.flatten(tag_preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:42.056483Z",
     "iopub.status.busy": "2022-09-04T13:59:42.056089Z",
     "iopub.status.idle": "2022-09-04T13:59:42.075570Z",
     "shell.execute_reply": "2022-09-04T13:59:42.073762Z",
     "shell.execute_reply.started": "2022-09-04T13:59:42.056449Z"
    }
   },
   "outputs": [],
   "source": [
    "# from tqdm import tqdm\n",
    "from time import sleep\n",
    "import gc\n",
    "\n",
    "def train(model, iterator, optimizer, criterion, clip, print_every):\n",
    "    epoch_loss = 0\n",
    "    epoch_acc = 0\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    # tepoch = tqdm(iterator)\n",
    "    for i,(x, y, l) in enumerate(iterator):\n",
    "        text = x.long().T.cuda()\n",
    "        tags = y.long().T.cuda()\n",
    "        src_len = l\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        # for param in model.parameters():\n",
    "          # param.grad = None\n",
    "        \n",
    "        #text = [sent len, batch size]\n",
    "        predictions, tag_labels, tag_preds = model(text, src_len, tags, 1)\n",
    "        \n",
    "        #predictions = [sent len, batch size, output dim]\n",
    "        #tags = [sent len, batch size]\n",
    "        \n",
    "        predictions = predictions.view(-1, predictions.shape[-1])\n",
    "        tags = tags.reshape(-1)\n",
    "        \n",
    "        #predictions = [sent len * batch size, output dim]\n",
    "        #tags = [sent len * batch size]\n",
    "        loss = criterion(predictions, tags)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "        # tepoch.set_postfix(loss=loss.item())\n",
    "        # sleep(0.1)\n",
    "\n",
    "    return epoch_loss / len(iterator)\n",
    "\n",
    "# from sklearn.metrics import precision_recall_fscore_support as score\n",
    "def evaluate(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    # y_preds = []\n",
    "    # y_trg = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (x, y, l) in enumerate(iterator):\n",
    "            src = x.long().T.to(device)\n",
    "            trg = y.long().T.to(device)\n",
    "            src_len = l.cuda()\n",
    "\n",
    "            output, tag_labels, tag_preds = model(src, src_len, trg, 0)\n",
    "        \n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.view(-1, output_dim)\n",
    "            trg = trg.reshape(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "          \n",
    "            loss = criterion(output, trg.cuda())\n",
    "            \n",
    "            epoch_loss += loss.item()\n",
    "            \n",
    "            # y_preds = y_preds + list(tag_labels.cpu())\n",
    "            # y_trg = y_trg + list(tag_preds.cpu())\n",
    "            # precision,recall,fscore,support=score(y_trg,y_preds)\n",
    "            # print(\"F1:\",fscore)\n",
    "\n",
    "        \n",
    "    return epoch_loss / len(iterator) \n",
    "\n",
    "def test(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    y_preds = []\n",
    "    y_trg = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (x, y, l) in enumerate(iterator):\n",
    "            if i%10 == 0:\n",
    "              print(i)\n",
    "              \n",
    "            src = x.long().T.to(device)\n",
    "            trg = y.long().T.to(device)\n",
    "            src_len = l.cuda()\n",
    "\n",
    "            output, tag_labels, tag_preds = model(src, src_len, trg, 1)\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.view(-1, output_dim)\n",
    "            trg = trg.reshape(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            y_preds = y_preds + list(tag_labels.cpu())\n",
    "            y_trg = y_trg + list(tag_preds.cpu())\n",
    "\n",
    "            loss = criterion(output, trg.cuda())\n",
    "            \n",
    "            epoch_loss += loss.detach().item()\n",
    "        \n",
    "    return epoch_loss / len(iterator) , y_preds, y_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:42.077609Z",
     "iopub.status.busy": "2022-09-04T13:59:42.077193Z",
     "iopub.status.idle": "2022-09-04T13:59:42.086468Z",
     "shell.execute_reply": "2022-09-04T13:59:42.085458Z",
     "shell.execute_reply.started": "2022-09-04T13:59:42.077575Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "def timeSince(since):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    return asMinutes(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:42.088634Z",
     "iopub.status.busy": "2022-09-04T13:59:42.087671Z",
     "iopub.status.idle": "2022-09-04T13:59:46.935302Z",
     "shell.execute_reply": "2022-09-04T13:59:46.934311Z",
     "shell.execute_reply.started": "2022-09-04T13:59:42.088522Z"
    },
    "id": "b5mjagPCiLy8",
    "outputId": "451ccd09-9f0f-498a-8104-04cf16629008"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117166\n",
      "27\n"
     ]
    }
   ],
   "source": [
    "INPUT_DIM = len(vocab2index.keys())\n",
    "OUTPUT_DIM = len(pos2index.keys())\n",
    "ENC_EMB_DIM = 300\n",
    "DEC_EMB_DIM = 300\n",
    "ENC_HID_DIM = 800\n",
    "DEC_HID_DIM = 800\n",
    "ENC_DROPOUT = 0.5\n",
    "DEC_DROPOUT = 0.5\n",
    "SRC_PAD_IDX = vocab2index[\"PAD\"]\n",
    "TRG_PAD_IDX = pos2index[\"PAD\"]\n",
    "\n",
    "print(INPUT_DIM)\n",
    "print(OUTPUT_DIM)\n",
    "\n",
    "attn = Attention(ENC_HID_DIM, DEC_HID_DIM).to(device)\n",
    "enc = Encoder(INPUT_DIM, ENC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, ENC_DROPOUT, SRC_PAD_IDX, pretrained_weights).to(device)\n",
    "dec = Decoder(OUTPUT_DIM, DEC_EMB_DIM, ENC_HID_DIM, DEC_HID_DIM, DEC_DROPOUT, attn).to(device)\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:46.937244Z",
     "iopub.status.busy": "2022-09-04T13:59:46.936853Z",
     "iopub.status.idle": "2022-09-04T13:59:46.948719Z",
     "shell.execute_reply": "2022-09-04T13:59:46.947480Z",
     "shell.execute_reply.started": "2022-09-04T13:59:46.937207Z"
    },
    "id": "60tBR5chiozF",
    "outputId": "dea72dac-da80-4ed4-e30c-0810a53bd5b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 15,057,827 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def init_weights(m):\n",
    "    for name, param in m.named_parameters():\n",
    "        if 'weight' in name:\n",
    "            nn.init.normal_(param.data, mean=0, std=0.01)\n",
    "        else:\n",
    "            nn.init.constant_(param.data, 0)\n",
    "            \n",
    "model.apply(init_weights)\n",
    "\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:46.951259Z",
     "iopub.status.busy": "2022-09-04T13:59:46.950637Z",
     "iopub.status.idle": "2022-09-04T13:59:46.957392Z",
     "shell.execute_reply": "2022-09-04T13:59:46.956301Z",
     "shell.execute_reply.started": "2022-09-04T13:59:46.951223Z"
    }
   },
   "outputs": [],
   "source": [
    "lr = 0.01\n",
    "optimizer = optim.Adam(model.parameters())\n",
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T13:59:46.959719Z",
     "iopub.status.busy": "2022-09-04T13:59:46.959271Z",
     "iopub.status.idle": "2022-09-04T15:36:12.208855Z",
     "shell.execute_reply": "2022-09-04T15:36:12.207800Z",
     "shell.execute_reply.started": "2022-09-04T13:59:46.959683Z"
    },
    "id": "BlfEf7D0mctG",
    "outputId": "0b9f7a9c-8605-42e6-ed3d-9ab7853a8d68"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "298\n",
      "9m 37s\n",
      "Epoch: 01, Train Loss: 1.779, Val. Loss: 8.635\n",
      "19m 13s\n",
      "Epoch: 02, Train Loss: 1.619, Val. Loss: 8.442\n",
      "28m 47s\n",
      "Epoch: 03, Train Loss: 1.421, Val. Loss: 5.729\n",
      "38m 22s\n",
      "Epoch: 04, Train Loss: 1.006, Val. Loss: 4.727\n",
      "47m 57s\n",
      "Epoch: 05, Train Loss: 0.898, Val. Loss: 3.407\n",
      "57m 31s\n",
      "Epoch: 06, Train Loss: 0.758, Val. Loss: 1.381\n",
      "67m 8s\n",
      "Epoch: 07, Train Loss: 0.685, Val. Loss: 0.949\n",
      "76m 43s\n",
      "Epoch: 08, Train Loss: 0.640, Val. Loss: 0.960\n",
      "86m 18s\n",
      "Epoch: 09, Train Loss: 0.605, Val. Loss: 0.860\n",
      "95m 52s\n",
      "Epoch: 10, Train Loss: 0.573, Val. Loss: 1.427\n",
      "0\n",
      "10\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95     32462\n",
      "         1.0       0.60      0.91      0.72     62929\n",
      "         3.0       0.85      0.67      0.75      2224\n",
      "         4.0       0.00      0.00      0.00    116332\n",
      "         5.0       0.56      0.88      0.68     89424\n",
      "         6.0       0.61      0.82      0.70     39709\n",
      "         7.0       0.69      0.40      0.51       171\n",
      "         8.0       0.70      0.34      0.46     10970\n",
      "         9.0       0.92      0.60      0.72        57\n",
      "        10.0       0.87      0.78      0.82       752\n",
      "        11.0       0.00      0.00      0.00        11\n",
      "        12.0       0.64      0.56      0.60    103980\n",
      "        13.0       0.79      0.51      0.62      2696\n",
      "        14.0       0.87      0.77      0.81     11637\n",
      "        15.0       0.45      0.61      0.52     30505\n",
      "        16.0       0.77      0.84      0.80      6088\n",
      "        17.0       0.80      0.51      0.63      1673\n",
      "        18.0       0.89      0.87      0.88     49178\n",
      "        19.0       1.00      0.18      0.31        99\n",
      "        20.0       0.90      0.82      0.86     37432\n",
      "        21.0       0.81      0.67      0.73     14552\n",
      "        22.0       0.87      0.76      0.81      5482\n",
      "        23.0       0.79      0.50      0.61      2724\n",
      "        24.0       0.31      0.89      0.45     21715\n",
      "        25.0       0.79      0.39      0.52      8472\n",
      "        26.0       0.54      0.38      0.45       176\n",
      "\n",
      "    accuracy                           0.63    651450\n",
      "   macro avg       0.69      0.60      0.61    651450\n",
      "weighted avg       0.55      0.63      0.57    651450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import gc\n",
    "from datetime import datetime\n",
    "\n",
    "N_EPOCHS = 10\n",
    "CLIP = 0.1\n",
    "\n",
    "# scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
    "print(len(train_dl))\n",
    "best_valid_loss = float('inf')\n",
    "start_time = time.time()\n",
    "for epoch in range(N_EPOCHS): \n",
    "    gc.collect()\n",
    "    train_loss = train(model, train_dl, optimizer, criterion, CLIP,30)\n",
    "    valid_loss = evaluate(model, val_dl, criterion) \n",
    "    \n",
    "    print(timeSince(start_time))\n",
    "    print(f'Epoch: {epoch+1:02}, Train Loss: {train_loss:.3f}, Val. Loss: {valid_loss:.3f}')\n",
    "    \n",
    "test_loss, y_preds, y_trg = test(model, test_dl, criterion)\n",
    "print(classification_report(y_preds,y_trg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T15:36:12.211098Z",
     "iopub.status.busy": "2022-09-04T15:36:12.210671Z",
     "iopub.status.idle": "2022-09-04T15:36:12.233660Z",
     "shell.execute_reply": "2022-09-04T15:36:12.232671Z",
     "shell.execute_reply.started": "2022-09-04T15:36:12.211058Z"
    },
    "id": "WV8VbtNsQxel"
   },
   "outputs": [],
   "source": [
    "def test(model, iterator, criterion):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    y_preds = []\n",
    "    y_trg = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i, (x, y, l) in enumerate(iterator):\n",
    "            if i%10 == 0:\n",
    "              print(i)\n",
    "              \n",
    "            src = x.long().T.to(device)\n",
    "            trg = y.long().T.to(device)\n",
    "            src_len = l.cuda()\n",
    "\n",
    "            output, tag_labels, tag_preds = model(src, src_len, trg, 1)\n",
    "\n",
    "            #trg = [trg len, batch size]\n",
    "            #output = [trg len, batch size, output dim]\n",
    "\n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.view(-1, output_dim)\n",
    "            trg = trg.reshape(-1)\n",
    "\n",
    "            #trg = [(trg len - 1) * batch size]\n",
    "            #output = [(trg len - 1) * batch size, output dim]\n",
    "\n",
    "            y_preds = y_preds + list(tag_labels.cpu())\n",
    "            y_trg = y_trg + list(tag_preds.cpu())\n",
    "\n",
    "            loss = criterion(output, trg.cuda())\n",
    "            \n",
    "            epoch_loss += loss.detach().item()\n",
    "        \n",
    "    return epoch_loss / len(iterator) , y_preds, y_trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-09-04T15:36:12.236344Z",
     "iopub.status.busy": "2022-09-04T15:36:12.235118Z",
     "iopub.status.idle": "2022-09-04T15:36:44.697835Z",
     "shell.execute_reply": "2022-09-04T15:36:44.696795Z",
     "shell.execute_reply.started": "2022-09-04T15:36:12.236308Z"
    },
    "id": "AXfsrcSN6-mz",
    "outputId": "9141575f-6e42-4831-efe9-12156c6f8277"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.95      0.95      0.95     32462\n",
      "         1.0       0.60      0.91      0.72     62929\n",
      "         3.0       0.85      0.67      0.75      2224\n",
      "         4.0       0.00      0.00      0.00    116332\n",
      "         5.0       0.56      0.88      0.68     89424\n",
      "         6.0       0.61      0.82      0.70     39709\n",
      "         7.0       0.69      0.40      0.51       171\n",
      "         8.0       0.70      0.34      0.46     10970\n",
      "         9.0       0.92      0.60      0.72        57\n",
      "        10.0       0.87      0.78      0.82       752\n",
      "        11.0       0.00      0.00      0.00        11\n",
      "        12.0       0.64      0.56      0.60    103980\n",
      "        13.0       0.79      0.51      0.62      2696\n",
      "        14.0       0.87      0.77      0.81     11637\n",
      "        15.0       0.45      0.61      0.52     30505\n",
      "        16.0       0.77      0.84      0.80      6088\n",
      "        17.0       0.80      0.51      0.63      1673\n",
      "        18.0       0.89      0.87      0.88     49178\n",
      "        19.0       1.00      0.18      0.31        99\n",
      "        20.0       0.90      0.82      0.86     37432\n",
      "        21.0       0.81      0.67      0.73     14552\n",
      "        22.0       0.87      0.76      0.81      5482\n",
      "        23.0       0.79      0.50      0.61      2724\n",
      "        24.0       0.31      0.89      0.45     21715\n",
      "        25.0       0.79      0.39      0.52      8472\n",
      "        26.0       0.54      0.38      0.45       176\n",
      "\n",
      "    accuracy                           0.63    651450\n",
      "   macro avg       0.69      0.60      0.61    651450\n",
      "weighted avg       0.55      0.63      0.57    651450\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "test_loss, y_preds, y_trg = test(model, test_dl, criterion)\n",
    "print(classification_report(y_preds,y_trg))\n",
    "# print(\"----------------------\")\n",
    "# lcm = np.lcm(y_preds,y_trg)\n",
    "# print(\"lcm :\" + str(lcm))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
