{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T4LSh6CyqsEG",
    "outputId": "7566e5cd-1a9f-45a8-a1be-53a922cf93b0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: hazm in /usr/local/lib/python3.7/dist-packages (0.7.0)\n",
      "Requirement already satisfied: nltk==3.3 in /usr/local/lib/python3.7/dist-packages (from hazm) (3.3)\n",
      "Requirement already satisfied: libwapiti>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from hazm) (0.2.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Requirement already satisfied: fasttext in /usr/local/lib/python3.7/dist-packages (0.9.2)\n",
      "Requirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.10.0)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.21.6)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (57.4.0)\n"
     ]
    }
   ],
   "source": [
    "#library imports\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import string\n",
    "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
    "from sklearn.metrics import mean_squared_error\n",
    "!pip install hazm\n",
    "!pip install fasttext\n",
    "from hazm import *\n",
    "import fasttext.util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dUedmSYCq9uh",
    "outputId": "c33e0cda-d73b-4846-a060-f18e9d69a07a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU is available\n"
     ]
    }
   ],
   "source": [
    "is_cuda = torch.cuda.is_available()\n",
    "if is_cuda:\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(\"GPU is available\")\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "  print(\"GPU not available, CPU used\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1z7odPkLtEG2"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "from hazm import *\n",
    "import re\n",
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()\n",
    "\n",
    "def remove_emojis_punctuations(text):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    text = re.sub(emoj, '', text)\n",
    "    punctuations = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~،؟'\n",
    "    text = text.translate(str.maketrans(punctuations, ' '*len(punctuations)))\n",
    "    from string import digits\n",
    "    digits = digits + \"۰۱۲۳۴۵۶۷۸۹\"\n",
    "    remove_digits = str.maketrans('', '', digits)\n",
    "    text = text.translate(remove_digits)\n",
    "    return text\n",
    "\n",
    "def preprocess_text(text):\n",
    "  return remove_emojis_punctuations(text)\n",
    "def preprocess_data_frame(data_frame, column=\"sent\"):\n",
    "  for index, row in data_frame.iterrows():\n",
    "      row[column] = remove_emojis_punctuations(row[column])\n",
    "      row[column] = normalizer.normalize(row[column])\n",
    "      for sent in sent_tokenize(row[column]):\n",
    "        for word in word_tokenize(row[column]):\n",
    "          if re.search(r'[a-zA-Z]', word):\n",
    "            row[column] = row[column].replace(word, \"\")\n",
    "          else:\n",
    "            new_word = lemmatizer.lemmatize(word)\n",
    "            if new_word.__contains__(\"#\"):\n",
    "              new_word = new_word.split(\"#\")[0]\n",
    "            \n",
    "            new_word = new_word.replace(\"\\u200c\",\" \")\n",
    "            row[column] = row[column].replace(word, new_word)\n",
    "  return data_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "guFMMZFr4LnW",
    "outputId": "fd32f44c-2d82-42fe-d477-a5ec2a105a22"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ],
   "source": [
    "ft = fasttext.load_model('/content/drive/MyDrive/NLP/cc.fa.300.bin')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "nKA3dF7o3JKA"
   },
   "outputs": [],
   "source": [
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    tokenized = word_tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "S1XOrftJriRt"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_train = pd.read_csv('/content/drive/MyDrive/NLP/train.txt', sep=\"\\t\", on_bad_lines='skip',header=None)\n",
    "df_train.columns = [\"sent\", \"mood\"]\n",
    "\n",
    "df_test = pd.read_csv('/content/drive/MyDrive/NLP/test.txt', sep=\"\\t\", on_bad_lines='skip',header=None)\n",
    "df_test.columns = [\"sent\", \"mood\"]\n",
    "\n",
    "df_all = df_train.append(df_test)\n",
    "df_all = preprocess_data_frame(df_all)\n",
    "df_train = preprocess_data_frame(df_train)\n",
    "df_test = preprocess_data_frame(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "BNDhsr9k22ec"
   },
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for index, row in df_all.iterrows():\n",
    "  for sent in sent_tokenize(row[\"sent\"]):\n",
    "    for word in word_tokenize(row[\"sent\"]):\n",
    "      if word not in all_words: \n",
    "        all_words.append(word)\n",
    "\n",
    "vocab2index = {\"\":0, \"UNK\":1}\n",
    "word_vector_dic = {}\n",
    "for word in all_words:\n",
    "  vocab2index[word] = len(vocab2index.keys())\n",
    "  if word not in word_vector_dic:\n",
    "    word_vector_dic[word] = ft.get_word_vector(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cjLZNqtX5Gav",
    "outputId": "ce8a665b-8efc-47bd-cf31-209e5b648897"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:9: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  if __name__ == '__main__':\n",
      "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:10: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray.\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "def encode_sentence(text, vocab2index, N=70):\n",
    "    tokenized = word_tokenize(text)\n",
    "    encoded = np.zeros(N, dtype=int)\n",
    "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in tokenized])\n",
    "    length = min(N, len(enc1))\n",
    "    encoded[:length] = enc1[:length]\n",
    "    return encoded, length\n",
    "\n",
    "df_train['encoded'] = df_train['sent'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))\n",
    "df_test['encoded'] = df_test['sent'].apply(lambda x: np.array(encode_sentence(x,vocab2index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "rKfbx1RA3t4s"
   },
   "outputs": [],
   "source": [
    "Encoder = LabelEncoder()\n",
    "y_train = Encoder.fit_transform(df_train[\"mood\"])\n",
    "y_test = Encoder.fit_transform(df_test[\"mood\"])\n",
    "\n",
    "\n",
    "X_test = pd.Series(df_test[\"encoded\"].values.tolist())\n",
    "y_test = np.array(y_test)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(df_train[\"encoded\"], y_train, test_size=0.25, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4nFhWcbKelvm",
    "outputId": "f6c62217-00d6-43a7-fc54-01124e55a1a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_test))\n",
    "print(type(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "XBZI1QmA1CHG"
   },
   "outputs": [],
   "source": [
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.y = Y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return torch.from_numpy(self.X[idx][0].astype(np.int32)), self.y[idx], self.X[idx][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_51x6meg1Em2"
   },
   "outputs": [],
   "source": [
    "train_ds = ReviewsDataset(list(X_train), y_train)\n",
    "valid_ds = ReviewsDataset(list(X_val), y_val)\n",
    "test_ds = ReviewsDataset(list(X_test), y_test)\n",
    "batch_size = 500\n",
    "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
    "val_dl = DataLoader(valid_ds, batch_size=batch_size)\n",
    "test_dl = DataLoader(test_ds, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "K5_kWPktyTu4"
   },
   "outputs": [],
   "source": [
    "del(ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "tl2BWkcRycaU"
   },
   "outputs": [],
   "source": [
    "def get_emb_matrix(emb_size = 300):\n",
    "    \"\"\" Creates embedding matrix from word vectors\"\"\"\n",
    "    vocab_size = len(word_vector_dic.keys()) + 2\n",
    "    vocab_to_idx = {}\n",
    "    vocab = [\"\", \"UNK\"]\n",
    "    W = np.zeros((vocab_size, emb_size), dtype=\"float32\")\n",
    "    W[0] = np.zeros(emb_size, dtype='float32') # adding a vector for padding\n",
    "    W[1] = np.random.uniform(-0.25, 0.25, emb_size) # adding a vector for unknown words \n",
    "    vocab_to_idx[\"UNK\"] = 1\n",
    "    i = 2\n",
    "    for word in word_vector_dic.keys():\n",
    "        if word in word_vector_dic:\n",
    "            W[i] = word_vector_dic[word]\n",
    "        else:\n",
    "            W[i] = np.random.uniform(-0.25,0.25, emb_size)\n",
    "        vocab_to_idx[word] = i\n",
    "        vocab.append(word)\n",
    "        i += 1   \n",
    "    return W, np.array(vocab), vocab_to_idx, vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "JOpwM0H8zDjG"
   },
   "outputs": [],
   "source": [
    "pretrained_weights, vocab, vocab2index, vocab_size = get_emb_matrix(emb_size = 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PvsokVjQ0OjT",
    "outputId": "4cb8e5e5-d8f2-4d2f-8492-3abf2871f21c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19141\n"
     ]
    }
   ],
   "source": [
    "print(len(word_vector_dic.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "sq6W48WzzcmY"
   },
   "outputs": [],
   "source": [
    "class LSTM_glove_vecs(torch.nn.Module) :\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, weights) :\n",
    "        super().__init__()\n",
    "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.embeddings.weight.data.copy_(torch.from_numpy(weights))\n",
    "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True)\n",
    "        self.linear = nn.Linear(hidden_dim, 7)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "    def forward(self, x, l):\n",
    "        x = self.embeddings(x)\n",
    "        x = self.dropout(x)\n",
    "        lstm_out, (ht, ct) = self.lstm(x)\n",
    "        return self.linear(ht[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "87NVVGmGTlOO"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "def train_model(model, epochs, lr):\n",
    "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
    "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
    "    print(epochs)\n",
    "    for i in range(epochs):\n",
    "        model.train()\n",
    "        sum_loss = 0.0\n",
    "        total = 0\n",
    "        for x, y, l in train_dl:\n",
    "            x = x.long()\n",
    "            y = y.long()\n",
    "            y_pred = model(x.cuda(), l.cuda())\n",
    "            optimizer.zero_grad()\n",
    "            loss = F.cross_entropy(y_pred.cuda(), y.cuda())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            sum_loss += loss.item()*y.shape[0]\n",
    "            total += y.shape[0]\n",
    "        val_loss, val_acc, val_rmse = validation_metrics(model, val_dl)\n",
    "        if i % 20 == 0:\n",
    "            print(\"epoch %d train loss %.3f, val loss %.3f, val accuracy %.3f, and val rmse %.3f\" % (i, sum_loss/total, val_loss, val_acc, val_rmse))\n",
    "\n",
    "def validation_metrics (model, valid_dl):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    sum_loss = 0.0\n",
    "    sum_rmse = 0.0\n",
    "    for x, y, l in valid_dl:\n",
    "        x = x.long().cuda()\n",
    "        y = y.long().cuda()\n",
    "        y_hat = model(x.cuda(), l.cuda())\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        correct = correct + (pred == y).float().sum()\n",
    "        total += y.shape[0]\n",
    "        sum_loss += loss.item()*y.shape[0]\n",
    "        a = mean_squared_error(pred.cpu(), y.unsqueeze(-1).cpu())\n",
    "        sum_rmse += math.sqrt(mean_squared_error(pred.cpu(), y.unsqueeze(-1).cpu()))*y.shape[0]\n",
    "    return sum_loss/total, correct/total, sum_rmse/total\n",
    "\n",
    "def test_metrics(model, test_dl):\n",
    "    model.to(torch.device(\"cpu\"))\n",
    "    model.eval()\n",
    "    predictions = []\n",
    "    labels = []\n",
    "  \n",
    "    for x, y, l in test_dl:\n",
    "        x = x.long()\n",
    "        y = y.long()\n",
    "        y_hat = model(x, l)\n",
    "        pred = torch.max(y_hat, 1)[1]\n",
    "        pred = list(pred.cpu().detach().numpy())\n",
    "        y = list(y.cpu().detach().numpy())\n",
    "        predictions += pred\n",
    "        labels += y\n",
    "\n",
    "    print(classification_report(labels,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GQHpPcOK3QiI",
    "outputId": "1569d88d-dc1a-467a-e420-1100283f9d4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300\n",
      "epoch 0 train loss 1.899, val loss 1.881, val accuracy 0.279, and val rmse 2.096\n",
      "epoch 20 train loss 1.787, val loss 1.785, val accuracy 0.273, and val rmse 2.164\n",
      "epoch 40 train loss 0.848, val loss 1.329, val accuracy 0.557, and val rmse 2.170\n",
      "epoch 60 train loss 0.375, val loss 1.611, val accuracy 0.575, and val rmse 1.916\n",
      "epoch 80 train loss 0.233, val loss 1.841, val accuracy 0.588, and val rmse 1.928\n",
      "epoch 100 train loss 0.156, val loss 1.996, val accuracy 0.585, and val rmse 1.952\n",
      "epoch 120 train loss 0.121, val loss 2.176, val accuracy 0.587, and val rmse 1.928\n",
      "epoch 140 train loss 0.111, val loss 2.355, val accuracy 0.589, and val rmse 1.968\n",
      "epoch 160 train loss 0.085, val loss 2.400, val accuracy 0.582, and val rmse 1.953\n",
      "epoch 180 train loss 0.062, val loss 2.448, val accuracy 0.586, and val rmse 1.957\n",
      "epoch 200 train loss 0.057, val loss 2.524, val accuracy 0.584, and val rmse 1.954\n",
      "epoch 220 train loss 0.067, val loss 2.372, val accuracy 0.587, and val rmse 1.885\n",
      "epoch 240 train loss 0.041, val loss 2.585, val accuracy 0.580, and val rmse 1.930\n",
      "epoch 260 train loss 0.069, val loss 2.594, val accuracy 0.597, and val rmse 1.960\n",
      "epoch 280 train loss 0.044, val loss 2.768, val accuracy 0.586, and val rmse 1.996\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.45      0.45      0.45       154\n",
      "           1       0.59      0.61      0.60        57\n",
      "           2       0.63      0.37      0.47       275\n",
      "           3       0.44      0.29      0.35        65\n",
      "           4       0.37      0.65      0.47       193\n",
      "           5       0.43      0.58      0.49       262\n",
      "           6       0.62      0.18      0.28       145\n",
      "\n",
      "    accuracy                           0.46      1151\n",
      "   macro avg       0.50      0.45      0.44      1151\n",
      "weighted avg       0.50      0.46      0.45      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LSTM_glove_vecs(vocab_size = vocab_size, embedding_dim = 300, hidden_dim = 50, weights = pretrained_weights)\n",
    "model.to(device)\n",
    "train_model(model, epochs=300, lr=0.01)\n",
    "test_metrics(model,test_dl)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "FinalFastText.ipynb",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
