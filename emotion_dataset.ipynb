{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "frJZvgYzogUt",
    "outputId": "62a06cea-1505-45a1-e1f2-e45249d4c97d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting hazm\n",
      "  Downloading hazm-0.7.0-py3-none-any.whl (316 kB)\n",
      "\u001b[K     |████████████████████████████████| 316 kB 7.8 MB/s \n",
      "\u001b[?25hCollecting libwapiti>=0.2.1\n",
      "  Downloading libwapiti-0.2.1.tar.gz (233 kB)\n",
      "\u001b[K     |████████████████████████████████| 233 kB 48.1 MB/s \n",
      "\u001b[?25hCollecting nltk==3.3\n",
      "  Downloading nltk-3.3.0.zip (1.4 MB)\n",
      "\u001b[K     |████████████████████████████████| 1.4 MB 44.4 MB/s \n",
      "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from nltk==3.3->hazm) (1.15.0)\n",
      "Building wheels for collected packages: nltk, libwapiti\n",
      "  Building wheel for nltk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for nltk: filename=nltk-3.3-py3-none-any.whl size=1394486 sha256=1e2ce1e05c48b585d6949f184d0af72dad5f53853fd33ba0e43792226996a3dc\n",
      "  Stored in directory: /root/.cache/pip/wheels/9b/fd/0c/d92302c876e5de87ebd7fc0979d82edb93e2d8d768bf71fac4\n",
      "  Building wheel for libwapiti (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for libwapiti: filename=libwapiti-0.2.1-cp37-cp37m-linux_x86_64.whl size=154950 sha256=da7dc9131b9087b0567c18043829bd4670f6f73077bfd8ab689cfb1d3eee0837\n",
      "  Stored in directory: /root/.cache/pip/wheels/ab/b2/5b/0fe4b8f5c0e65341e8ea7bb3f4a6ebabfe8b1ac31322392dbf\n",
      "Successfully built nltk libwapiti\n",
      "Installing collected packages: nltk, libwapiti, hazm\n",
      "  Attempting uninstall: nltk\n",
      "    Found existing installation: nltk 3.7\n",
      "    Uninstalling nltk-3.7:\n",
      "      Successfully uninstalled nltk-3.7\n",
      "Successfully installed hazm-0.7.0 libwapiti-0.2.1 nltk-3.3\n"
     ]
    }
   ],
   "source": [
    "!pip install hazm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "id": "xhQ8SKbfZ3dF"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_train = pd.read_csv('train.txt', sep=\"\\t\", on_bad_lines='skip',header=None)\n",
    "df_train.columns = [\"sent\", \"mood\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NOzuHsf5ePJ5",
    "outputId": "2c4cd171-be30-4efe-97f8-4ed9befa35ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                sent   mood\n",
      "0  خیلی کوچیک هستن و سایزشون بدرد نمیخوره میخوام ...    SAD\n",
      "1     از صدای پرنده دم دمای صبح متنفرم متنفرم متنفرم   HATE\n",
      "2   \"کیفیتش خیلی خوبه با شک خریدم ولی واقعا راضیم...    SAD\n",
      "3  چون همش با دوربین ثبت شده ، ایا میشه اعتراض زد...  OTHER\n",
      "4              اين وضع ب طرز خنده داري گريه داره ...    SAD\n",
      "5  خب من رسما از یک نفر متنفرم،چون از گربه بدش می...   HATE\n",
      "6  داشتم خواب میدیدم یهو توی خواب گفتم بیاین درین...   FEAR\n",
      "7               اصلا ارزش خرید نداره فقط رو مخ میره\"  ANGRY\n",
      "8  اونجایه آدمه مفعول ودروغگو...عجب خرایی داریم و...  ANGRY\n",
      "9  من این گوشی رو اعصابم بهم ریخت کوبیدم تودیوار ...  HAPPY\n"
     ]
    }
   ],
   "source": [
    "print(df_train.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "id": "6_PhwabRie80"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def remove_emojis_punctuations(text):\n",
    "    emoj = re.compile(\"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "        u\"\\U00002500-\\U00002BEF\"  # chinese char\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U00002702-\\U000027B0\"\n",
    "        u\"\\U000024C2-\\U0001F251\"\n",
    "        u\"\\U0001f926-\\U0001f937\"\n",
    "        u\"\\U00010000-\\U0010ffff\"\n",
    "        u\"\\u2640-\\u2642\" \n",
    "        u\"\\u2600-\\u2B55\"\n",
    "        u\"\\u200d\"\n",
    "        u\"\\u23cf\"\n",
    "        u\"\\u23e9\"\n",
    "        u\"\\u231a\"\n",
    "        u\"\\ufe0f\"  # dingbats\n",
    "        u\"\\u3030\"\n",
    "                      \"]+\", re.UNICODE)\n",
    "    text = re.sub(emoj, '', text)\n",
    "    punctuations = '!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~،؟'\n",
    "    text = text.translate(str.maketrans(punctuations, ' '*len(punctuations)))\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "dCJxqRrLoprK"
   },
   "outputs": [],
   "source": [
    "from hazm import *\n",
    "normalizer = Normalizer()\n",
    "stemmer = Stemmer()\n",
    "lemmatizer = Lemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "id": "Mwqhkgt0jOiu"
   },
   "outputs": [],
   "source": [
    "def preprocess_text(data_frame):\n",
    "  for index, row in data_frame.iterrows():\n",
    "      if index%10 == 0:\n",
    "        print(row['sent'])\n",
    "      row['sent'] = remove_emojis_punctuations(row['sent'])\n",
    "      row['sent'] = normalizer.normalize(row['sent'])\n",
    "      for sent in sent_tokenize(row['sent']):\n",
    "        for word in word_tokenize(row['sent']):\n",
    "          if re.search(r'[a-zA-Z]', word):\n",
    "            row['sent'] = row['sent'].replace(word, \"\")\n",
    "          else:\n",
    "            # new_word = stemmer.stem(word)\n",
    "            new_word = lemmatizer.lemmatize(word)\n",
    "            if new_word.__contains__(\"#\"):\n",
    "              new_word = new_word.split(\"#\")[0]\n",
    "            \n",
    "            row['sent'] = row['sent'].replace(word, new_word)\n",
    "      if index%10 == 0:\n",
    "        print(row['sent'])\n",
    "        print(\"-----------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RtKLy0Gpq3UM",
    "outputId": "8600fa97-d1df-4c41-865b-bb76634b457a"
   },
   "outputs": [],
   "source": [
    "preprocess_text(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ig4YudmcqNpd",
    "outputId": "648f3548-3125-4315-a428-70ce4ac87082"
   },
   "outputs": [],
   "source": [
    "#TEST data\n",
    "df_test = pd.read_csv('test.txt', sep=\"\\t\", on_bad_lines='skip',header=None)\n",
    "df_test.columns = [\"sent\", \"mood\"]\n",
    "preprocess_text(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "UrN--gvCrBlI"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "Encoder = LabelEncoder()\n",
    "train_y = Encoder.fit_transform(df_train[\"mood\"])\n",
    "test_y = Encoder.fit_transform(df_test[\"mood\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "id": "6FX767GajOQm"
   },
   "outputs": [],
   "source": [
    "# TfidfVectorizer\n",
    "from sklearn import model_selection, naive_bayes, svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "tfidf_vect = TfidfVectorizer()\n",
    "tfidf_vect.fit(df_train['sent'].append(df_test['sent']))\n",
    "train_X_Tfidf = tfidf_vect.transform(df_train['sent'])\n",
    "test_X_Tfidf = tfidf_vect.transform(df_test['sent'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l9_fPeMFSXDO",
    "outputId": "3fc4a84f-b861-4f36-c617-5fc18123506c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Accuracy Score ->  20.677671589921808\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.06      0.11       154\n",
      "           1       1.00      0.04      0.07        57\n",
      "           2       1.00      0.00      0.01       275\n",
      "           3       0.00      0.00      0.00        65\n",
      "           4       0.17      0.99      0.30       193\n",
      "           5       0.89      0.13      0.23       262\n",
      "           6       0.00      0.00      0.00       145\n",
      "\n",
      "    accuracy                           0.21      1151\n",
      "   macro avg       0.55      0.17      0.10      1151\n",
      "weighted avg       0.62      0.21      0.12      1151\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# NB classifier\n",
    "\n",
    "naive = naive_bayes.MultinomialNB()\n",
    "naive.fit(train_X_Tfidf,train_y)\n",
    "\n",
    "predictions_nb = naive.predict(test_X_Tfidf)\n",
    "print(\"Naive Bayes Accuracy Score -> \",accuracy_score(predictions_nb, test_y)*100)\n",
    "print(classification_report(test_y, predictions_nb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DsOBmTlhvJhW",
    "outputId": "38a7cb46-48c3-4fd9-c099-46ab60f51a79"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM Accuracy Score ->  41.09470026064292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.34      0.40       154\n",
      "           1       0.70      0.56      0.62        57\n",
      "           2       0.68      0.20      0.31       275\n",
      "           3       0.33      0.12      0.18        65\n",
      "           4       0.25      0.82      0.39       193\n",
      "           5       0.63      0.55      0.59       262\n",
      "           6       0.62      0.16      0.25       145\n",
      "\n",
      "    accuracy                           0.41      1151\n",
      "   macro avg       0.53      0.39      0.39      1151\n",
      "weighted avg       0.54      0.41      0.40      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# SVM\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "\n",
    "svm = SVC(C=1.0, kernel='linear', degree=3, gamma='auto')\n",
    "svm.fit(train_X_Tfidf,train_y)\n",
    "predictions_svm = svm.predict(test_X_Tfidf)\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(predictions_svm, test_y)*100)\n",
    "print(classification_report(test_y, predictions_svm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 411
    },
    "id": "AotU3zy_3xsU",
    "outputId": "15b5775c-0da5-4685-fd3e-de691db57201"
   },
   "outputs": [],
   "source": [
    "# SVM with GridSearchCV\n",
    "param_grid = {'C': [0.1, 1, 10, 100, 1000],\n",
    "              'degree' : [2,3,4],\n",
    "              'gamma': [1, 0.1, 0.01, 0.001, 0.0001],\n",
    "              'kernel': ['linear']}\n",
    " \n",
    "grid_svm = GridSearchCV(SVC(), param_grid, refit = True, verbose = 2,cv = 2, n_jobs=-1)\n",
    "grid_svm.fit(train_X_Tfidf,train_y)\n",
    "grid_svm_predictions = grid_svm.predict(test_X_Tfidf)\n",
    "\n",
    "print(\"SVM Accuracy Score -> \",accuracy_score(grid_svm_predictions, test_y)*100)\n",
    "print(classification_report(test_y, grid_svm_predictions))\n",
    "print(grid_svm.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VoIWI66QBM8l",
    "outputId": "91f759f5-fb07-485d-e3ce-e42f6751e6ee"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN Accuracy Score ->  34.231103388357944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.15      0.21       154\n",
      "           1       0.34      0.40      0.37        57\n",
      "           2       0.43      0.56      0.48       275\n",
      "           3       0.11      0.25      0.15        65\n",
      "           4       0.31      0.32      0.31       193\n",
      "           5       0.42      0.29      0.35       262\n",
      "           6       0.31      0.28      0.29       145\n",
      "\n",
      "    accuracy                           0.34      1151\n",
      "   macro avg       0.32      0.32      0.31      1151\n",
      "weighted avg       0.36      0.34      0.34      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors=7)\n",
    "knn = knn.fit(train_X_Tfidf, train_y)\n",
    "predicted_knn = knn.predict(test_X_Tfidf)\n",
    "\n",
    "print(\"KNN Accuracy Score -> \",accuracy_score(predicted_knn, test_y)*100)\n",
    "print(classification_report(test_y, predicted_knn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1KDJEGdCQNu",
    "outputId": "f1a58270-3e14-4dc1-ec5d-54141892d0f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Accuracy Score ->  35.186794092093834\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.31      0.27      0.29       154\n",
      "           1       0.51      0.56      0.53        57\n",
      "           2       0.43      0.19      0.27       275\n",
      "           3       0.34      0.23      0.28        65\n",
      "           4       0.25      0.61      0.36       193\n",
      "           5       0.44      0.40      0.42       262\n",
      "           6       0.47      0.27      0.34       145\n",
      "\n",
      "    accuracy                           0.35      1151\n",
      "   macro avg       0.39      0.36      0.36      1151\n",
      "weighted avg       0.39      0.35      0.34      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree = decision_tree.fit(train_X_Tfidf,train_y)\n",
    "predictions_decision_tree = decision_tree.predict(test_X_Tfidf)\n",
    "\n",
    "print(\"Decision Tree Accuracy Score -> \",accuracy_score(predictions_decision_tree, test_y)*100)\n",
    "print(classification_report(test_y, predictions_decision_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8iuAIu4JMGLt",
    "outputId": "26120761-99f2-4c95-e02e-fd360370323d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "Decision Tree2 Accuracy Score ->  35.79496090356212\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree with GridSearchCV\n",
    "\n",
    "params = {'criterion': ['entropy', 'gini'], 'max_depth': [4,8,20,30,40,70,90,150]}\n",
    "grid_decision_tree = GridSearchCV(DecisionTreeClassifier(), params, verbose=2, cv=3,n_jobs=-1)\n",
    "grid_decision_tree = grid_decision_tree.fit(train_X_Tfidf,train_y)\n",
    "predictions_grid_decision_tree = grid_decision_tree.predict(test_X_Tfidf)\n",
    "print(\"Decision Tree with GridSearchCV Accuracy Score -> \",accuracy_score(predictions_grid_decision_tree, test_y)*100)\n",
    "print(classification_report(test_y, predictions_grid_decision_tree))\n",
    "print(grid_decision_tree.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XzTW9r5_C9dh",
    "outputId": "c46a70f2-0aa0-4724-ef38-99319ddbc9b3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy Score ->  35.79496090356212\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.21      0.29       154\n",
      "           1       0.60      0.60      0.60        57\n",
      "           2       0.60      0.14      0.22       275\n",
      "           3       0.35      0.14      0.20        65\n",
      "           4       0.22      0.92      0.36       193\n",
      "           5       0.79      0.31      0.44       262\n",
      "           6       0.65      0.19      0.30       145\n",
      "\n",
      "    accuracy                           0.35      1151\n",
      "   macro avg       0.53      0.36      0.34      1151\n",
      "weighted avg       0.56      0.35      0.33      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest = random_forest.fit(train_X_Tfidf,train_y)\n",
    "predictions_random_forest = random_forest_clf.predict(test_X_Tfidf)\n",
    "\n",
    "print(\"Random Forest Accuracy Score -> \",accuracy_score(y_pred, test_y)*100)\n",
    "print(classification_report(test_y, predictions_random_forest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkDkbTvDEpei",
    "outputId": "b552bc70-28ff-47cc-ec50-ce452cbd1703"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boosting Accuracy Score ->  16.85490877497828\n"
     ]
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "gradient_boosting = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_depth=2, random_state=0)\n",
    "gradient_boosting = gradient_boosting.fit(train_X_Tfidf,train_y)\n",
    "predictions_gradient_boosting = gradient_boosting.predict(test_X_Tfidf)\n",
    "\n",
    "print(\"Gradient Boosting Accuracy Score -> \",accuracy_score(predictions_gradient_boosting, test_y)*100)\n",
    "print(classification_report(test_y, predictions_gradient_boosting))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 429
    },
    "id": "wZd2ehN8U0I5",
    "outputId": "166896be-8c77-4a29-c135-2595b4d9f449"
   },
   "outputs": [],
   "source": [
    "# Gradient Boosting with GridSearchCV\n",
    "params = {'n_estimators': [10,20,30], 'max_depth': [2,10,20,30,70,150], 'random_state' : [0,5,10]}\n",
    "grid_gradient_boosting = GridSearchCV(GradientBoostingClassifier(), params, verbose=2, cv=2,n_jobs=-1)\n",
    "grid_gradient_boosting = grid_gradient_boosting.fit(train_X_Tfidf,train_y)\n",
    "predictions_grid_gradient_boosting = grid_gradient_boosting.predict(test_X_Tfidf)\n",
    "print(\"Decision Tree with GridSearchCV Accuracy Score -> \",accuracy_score(predictions_grid_gradient_boosting, test_y)*100)\n",
    "print(classification_report(test_y, predictions_grid_gradient_boosting))\n",
    "\n",
    "print(grid_gradient_boosting.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7yK9uTWeG_Uh",
    "outputId": "bdfddee2-ef2e-4ce9-8c39-62f3087a8a7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XGBoost Accuracy Score ->  40.660295395308424\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.53      0.31      0.39       154\n",
      "           1       0.63      0.72      0.67        57\n",
      "           2       0.59      0.22      0.32       275\n",
      "           3       0.47      0.22      0.29        65\n",
      "           4       0.25      0.78      0.38       193\n",
      "           5       0.59      0.46      0.51       262\n",
      "           6       0.62      0.24      0.35       145\n",
      "\n",
      "    accuracy                           0.41      1151\n",
      "   macro avg       0.52      0.42      0.42      1151\n",
      "weighted avg       0.52      0.41      0.40      1151\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# XGBoost\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100, n_jobs=-1,max_depth = 10)\n",
    "xgb.fit(train_X_Tfidf,train_y)\n",
    "predictions_xgb = xgb.predict(test_X_Tfidf)\n",
    "\n",
    "print(\"XGBoost Accuracy Score -> \",accuracy_score(predictions_xgb, test_y)*100)\n",
    "print(classification_report(test_y, predictions_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iDUhwmkJPF6O",
    "outputId": "87ed4f13-c90a-4467-e091-15fd44b52921"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 24 candidates, totalling 48 fits\n"
     ]
    }
   ],
   "source": [
    "# XGBoost with GridSearchCV\n",
    "parameters = {\n",
    "    \"max_depth\":[2, 10, 6, 12],\n",
    "    \"learning_rate\":[0.3, 0.1, 0.03],\n",
    "    \"n_estimators\":[20,100],\n",
    "    \"n_jobs\" : [-1]}\n",
    "\n",
    "grid_xgb = GridSearchCV(\n",
    "    estimator=XGBClassifier(),\n",
    "    param_grid=parameters,\n",
    "    scoring = 'roc_auc',\n",
    "    n_jobs = -1,\n",
    "    cv = 2,\n",
    "    verbose=True\n",
    ")\n",
    "grid_xgb = grid_xgb.fit(train_X_Tfidf,train_y)\n",
    "\n",
    "print(model_gs.best_params_)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "emotion_dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
